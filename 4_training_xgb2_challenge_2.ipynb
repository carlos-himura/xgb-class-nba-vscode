{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb247bc",
   "metadata": {},
   "source": [
    "Traning, and Experiments with Feature Engineering and Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409f8179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>efficiency</th>\n",
       "      <th>points</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>blocks_per_min</th>\n",
       "      <th>turnovers_per_min</th>\n",
       "      <th>team_LAL</th>\n",
       "      <th>opponent_GSW</th>\n",
       "      <th>team_CHA</th>\n",
       "      <th>steals_per_min</th>\n",
       "      <th>team_MIA</th>\n",
       "      <th>steals</th>\n",
       "      <th>points_per_min</th>\n",
       "      <th>opponent_IND</th>\n",
       "      <th>opponent_CHA</th>\n",
       "      <th>opponent_DAL</th>\n",
       "      <th>blocks</th>\n",
       "      <th>position_SF</th>\n",
       "      <th>team_OKC</th>\n",
       "      <th>opponent_DEN</th>\n",
       "      <th>team_DAL</th>\n",
       "      <th>assists_per_min</th>\n",
       "      <th>team_BKN</th>\n",
       "      <th>team_CHI</th>\n",
       "      <th>opponent_LAL</th>\n",
       "      <th>efficiency_per_min</th>\n",
       "      <th>team_HOU</th>\n",
       "      <th>opponent_CLE</th>\n",
       "      <th>opponent_UTA</th>\n",
       "      <th>opponent_LAC</th>\n",
       "      <th>opponent_OKC</th>\n",
       "      <th>scoring_consistency</th>\n",
       "      <th>team_NOP</th>\n",
       "      <th>game_location_Home</th>\n",
       "      <th>age</th>\n",
       "      <th>assists</th>\n",
       "      <th>rebounds_per_min</th>\n",
       "      <th>team_GSW</th>\n",
       "      <th>usage_rate</th>\n",
       "      <th>team_MIN</th>\n",
       "      <th>opponent_MIL</th>\n",
       "      <th>opponent_NOP</th>\n",
       "      <th>age_bin_prime</th>\n",
       "      <th>three_pct</th>\n",
       "      <th>pm_bin_neutral</th>\n",
       "      <th>position_PG</th>\n",
       "      <th>team_PHI</th>\n",
       "      <th>opponent_NYK</th>\n",
       "      <th>opponent_ORL</th>\n",
       "      <th>minutes_played</th>\n",
       "      <th>team_SAC</th>\n",
       "      <th>opponent_DET</th>\n",
       "      <th>rest_days</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>team_TOR</th>\n",
       "      <th>impact_metric</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>team_DET</th>\n",
       "      <th>position_PF</th>\n",
       "      <th>team_CLE</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>opponent_SAC</th>\n",
       "      <th>opponent_SAS</th>\n",
       "      <th>team_LAC</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.918030</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>51.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983606</td>\n",
       "      <td>79.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.197411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.902912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.453074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.100324</td>\n",
       "      <td>68.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052910</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.587300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.211640</td>\n",
       "      <td>0</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>78.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.579999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>68.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.043165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.856114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0.359712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.791367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.079137</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   efficiency  points  plus_minus  turnovers  blocks_per_min  \\\n",
       "0          12       9          -3          2        0.081967   \n",
       "1          37      15           1          0        0.064725   \n",
       "2          16      11          -2          2        0.000000   \n",
       "3          15      12           7          3        0.000000   \n",
       "4          29      16           7          2        0.000000   \n",
       "\n",
       "   turnovers_per_min  team_LAL  opponent_GSW  team_CHA  steals_per_min  \\\n",
       "0           0.163934         0             0         0        0.081967   \n",
       "1           0.000000         0             0         0        0.032362   \n",
       "2           0.105820         0             0         0        0.052910   \n",
       "3           0.150000         0             0         0        0.000000   \n",
       "4           0.071942         0             0         0        0.035971   \n",
       "\n",
       "   team_MIA  steals  points_per_min  opponent_IND  opponent_CHA  opponent_DAL  \\\n",
       "0         0       1        0.737705             0             0             0   \n",
       "1         0       1        0.485437             0             0             0   \n",
       "2         0       1        0.582011             0             0             0   \n",
       "3         0       0        0.600000             0             0             0   \n",
       "4         0       1        0.575540             0             0             0   \n",
       "\n",
       "   blocks  position_SF  team_OKC  opponent_DEN  team_DAL  assists_per_min  \\\n",
       "0       1            0         0             0         0         0.000000   \n",
       "1       2            0         0             0         0         0.161812   \n",
       "2       0            0         0             0         0         0.105820   \n",
       "3       0            0         0             0         0         0.100000   \n",
       "4       0            0         0             0         0         0.143885   \n",
       "\n",
       "   team_BKN  team_CHI  opponent_LAL  efficiency_per_min  team_HOU  \\\n",
       "0         0         0             0            0.983606         0   \n",
       "1         0         0             0            1.197411         0   \n",
       "2         0         0             0            0.846561         0   \n",
       "3         0         0             0            0.750000         0   \n",
       "4         0         0             0            1.043165         0   \n",
       "\n",
       "   opponent_CLE  opponent_UTA  opponent_LAC  opponent_OKC  \\\n",
       "0             0             0             0             0   \n",
       "1             0             0             0             0   \n",
       "2             0             0             0             0   \n",
       "3             0             0             0             0   \n",
       "4             0             0             0             0   \n",
       "\n",
       "   scoring_consistency  team_NOP  game_location_Home  age  assists  \\\n",
       "0            37.918030         1                   1   25        0   \n",
       "1            19.902912         0                   0   25        5   \n",
       "2            27.587300         0                   0   30        2   \n",
       "3            29.579999         0                   0   27        2   \n",
       "4            19.856114         0                   0   29        4   \n",
       "\n",
       "   rebounds_per_min  team_GSW  usage_rate  team_MIN  opponent_MIL  \\\n",
       "0          0.245902         0    0.901639         0             0   \n",
       "1          0.453074         0    0.647249         0             0   \n",
       "2          0.211640         0    0.793651         0             0   \n",
       "3          0.200000         0    0.850000         0             0   \n",
       "4          0.359712         0    0.791367         0             0   \n",
       "\n",
       "   opponent_NOP  age_bin_prime  three_pct  pm_bin_neutral  position_PG  \\\n",
       "0             0              1       19.6               0            0   \n",
       "1             0              1       31.2               1            0   \n",
       "2             1              0       28.0               0            0   \n",
       "3             0              1       45.8               0            0   \n",
       "4             0              0       22.5               0            0   \n",
       "\n",
       "   team_PHI  opponent_NYK  opponent_ORL  minutes_played  team_SAC  \\\n",
       "0         0             0             0            12.2         0   \n",
       "1         0             0             0            30.9         0   \n",
       "2         0             0             0            18.9         0   \n",
       "3         0             0             0            20.0         0   \n",
       "4         1             0             1            27.8         0   \n",
       "\n",
       "   opponent_DET  rest_days  fg_pct  team_TOR  impact_metric  ft_pct  team_DET  \\\n",
       "0             0          2    51.4         0       0.983606    79.9         0   \n",
       "1             0          1    41.0         0       1.100324    68.1         0   \n",
       "2             0          2    47.4         0       0.899471    78.2         0   \n",
       "3             0          2    49.3         0       0.900000    68.1         0   \n",
       "4             0          1    34.5         0       1.079137    76.0         0   \n",
       "\n",
       "   position_PF  team_CLE  rebounds  opponent_SAC  opponent_SAS  team_LAC  \\\n",
       "0            0         0         3             0             0         0   \n",
       "1            0         0        14             0             0         0   \n",
       "2            1         0         4             0             0         0   \n",
       "3            0         0         4             0             0         0   \n",
       "4            0         0        10             0             0         0   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       1  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First experiment without including feature engineering\n",
    "\n",
    "import pandas as pd\n",
    "df_preprocessed = pd.read_csv('Datasets/ds_feature_eng.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24003a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Rows: 5400 -  Validation set Rows: 1800 -  Test set Rows: 1800\n"
     ]
    }
   ],
   "source": [
    "# Test split for the experiment without feature engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Defining features and target\n",
    "X_1 = df_preprocessed.drop(columns='target')\n",
    "y_1 = df_preprocessed['target']\n",
    "\n",
    "# Test Split (20% of total data)\n",
    "X_1_train_valid, X_1_test, y_1_train_valid, y_1_test = train_test_split(\n",
    "    X_1, y_1, test_size=0.2, random_state=12345\n",
    ")\n",
    "\n",
    "# Validation split (25% of the remaining 80% â†’ 20% of total)\n",
    "X_1_train, X_1_valid, y_1_train, y_1_valid = train_test_split(\n",
    "    X_1_train_valid, y_1_train_valid, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Training set Rows: {X_1_train.shape[0]} - \",\n",
    "    f\"Validation set Rows: {X_1_valid.shape[0]} - \",\n",
    "    f\"Test set Rows: {X_1_test.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88024cd",
   "metadata": {},
   "source": [
    "Checking Class Balance in the Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559bf204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts\n",
      "target\n",
      "0    3212\n",
      "1    2188\n",
      "Name: count, dtype: int64\n",
      "class Proportions\n",
      "target\n",
      "0    0.594815\n",
      "1    0.405185\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_train is a Pandas Series\n",
    "# The primary reason for checking the class balance is to prevent the model from being biased toward the majority class.\n",
    "class_counts = y_1_train.value_counts()\n",
    "print(\"class counts\")\n",
    "print(class_counts)\n",
    "\n",
    "class_proportions = y_1_train.value_counts(normalize=True)\n",
    "print(\"class Proportions\")\n",
    "print(class_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453e5bc",
   "metadata": {},
   "source": [
    "Class Balance Conclusion:\n",
    "- The dataset has a ~60/40 split between the two classes.\n",
    "- Is this imbalanced? Yes, it is imbalanced because the classes are not equal (50/50).\n",
    "- Is it severely imbalanced? No. A severe imbalance is usually considered to be anything worse than 80/20 or 90/10.\n",
    "\n",
    "Implications:\n",
    "- It is manageable, but it still requires attention when predicting the minority class.\n",
    "- Better to use the Precision, Recall, F1-Score, and ROC AUC. To check how well perform with the minotry class.\n",
    "- Adjust class weighting: for XGB set the \"scale_pos_weight\" parameter. Starting value is the ratio of negative to positive samples 3212/2188 = 1.47. It tells the model to give the moniroty class 1.47 times the importance of the majority class.\n",
    "\n",
    "Later conclusion:\n",
    "- Conclusion about adding the balacing:\n",
    "  - Recall improve: model is now much better at detecting the minority class (your positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f062d0a",
   "metadata": {},
   "source": [
    "MLflow Experiment Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c3f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching by Experiment Tag - Project Name:\n",
      "<Experiment: artifact_location='mlflow-artifacts:/982562299770504179', creation_time=1764714729591, experiment_id='982562299770504179', last_update_time=1764714729591, lifecycle_stage='active', name='XGBoost_Classification_Feat_Eng', tags={'mlflow.note.content': 'This is the WZ challenge about NBA player '\n",
      "                        'performance. This experiment contains an XGBoost '\n",
      "                        'model with hyperparameter tuning using Hyperopt.',\n",
      " 'project_manager': 'carlos_himura',\n",
      " 'project_name': 'nba_binary_classification',\n",
      " 'team': 'data_science'}>\n"
     ]
    }
   ],
   "source": [
    "# --- Create MLflow Experiment ---\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000/\")\n",
    "\n",
    "# Set up MLflow experiment\n",
    "experiment_description = (\n",
    "    \"This is the WZ challenge about NBA player performance. \"\n",
    "    \"This experiment contains an XGBoost model with hyperparameter tuning using Hyperopt.\"\n",
    ")\n",
    "experiment_tags = {\n",
    "    \"team\": \"data_science\",\n",
    "    \"project_manager\": \"carlos_himura\",\n",
    "    \"project_name\": \"nba_binary_classification\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "experiment_name = \"XGBoost_Classification_Feat_Eng\"\n",
    "xgboost_experiment = client.create_experiment(name = experiment_name, tags = experiment_tags)\n",
    "\n",
    "search_experiment = client.search_experiments(\n",
    "  filter_string=\"tags.`project_name` = 'nba_binary_classification'\"\n",
    ")\n",
    "print(\"Searching by Experiment Tag - Project Name:\")\n",
    "print(search_experiment[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5e88b",
   "metadata": {},
   "source": [
    "Model Training with Hyperopt and with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5dc9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:36<00:00,  2.17s/trial, best loss: -0.9325170707526028]\n",
      "\n",
      " Best Hyperopt Parameters:\n",
      "{'colsample_bytree': np.float64(0.92790914912747), 'gamma': np.float64(11.223555562043511), 'learning_rate': np.float64(0.2576999175353665), 'max_depth': 4, 'min_child_weight': 15, 'n_estimators': 1400, 'subsample': np.float64(0.824988649268367)}\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "Accuracy: 0.8517\n",
      "ROC AUC: 0.9324\n",
      "Precision: 0.8202\n",
      "Recall (Sensitivity): 0.8077\n",
      "F1-Score: 0.8139\n",
      "\n",
      "ðŸ”· Validation Confusion Matrix:\n",
      "[[True_Pos False_Pos]\n",
      "[False_Neg True_Neg]]\n",
      "[[949 128]\n",
      " [139 584]]\n",
      "\n",
      "----------------------------------------\n",
      "ðŸ“Š Test Results:\n",
      "Accuracy: 0.8500\n",
      "ROC AUC: 0.9289\n",
      "Precision: 0.8160\n",
      "Recall (Sensitivity): 0.7852\n",
      "F1-Score: 0.8003\n",
      "\n",
      "ðŸ”· Test Confusion Matrix:\n",
      "[[True_Pos False_Pos]\n",
      "[False_Neg True_Neg]]\n",
      "[[989 122]\n",
      " [148 541]]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# NOTE: The ratio for scale_pos_weight is calculated from your class counts (3212 / 2188)\n",
    "# This parameter is fixed here as it directly addresses the known data imbalance.\n",
    "CLASS_WEIGHT_RATIO = 3212 / 2188 \n",
    "\n",
    "# --- 1. Define the Search Space ---\n",
    "# Defining the range of values that Hyperopt will test for each hyperparameter.\n",
    "# Using the defaults as a guide to create the ranges.\n",
    "\n",
    "search_space = {\n",
    "    \"n_estimators\":     hp.quniform(\"n_estimators\", 200, 1500, 50), # Number of trees\n",
    "    \"max_depth\":        hp.quniform(\"max_depth\", 3, 6, 1), # Maximum depth of each tree\n",
    "    \"learning_rate\":    hp.loguniform(\"learning_rate\", np.log(0.01), np.log(0.3)), # Boosting learning rate\n",
    "    \"subsample\":        hp.uniform(\"subsample\", 0.8, 1.0), # % of rows sampled per tree\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.75, 1.0), # % of features sampled per tree\n",
    "    \"gamma\":            hp.uniform(\"gamma\", 0, 20), # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    \"min_child_weight\": hp.quniform(\"min_child_weight\", 5, 20, 1), # It acts as a regularization term to prevent the model from learning relationships that are too specific to the training data\n",
    "}\n",
    "\n",
    "# --- 2. Define the objective function ---\n",
    "def objective(params):\n",
    "\n",
    "    # Convert integer params\n",
    "    params[\"n_estimators\"]     = int(params[\"n_estimators\"])\n",
    "    params[\"max_depth\"]        = int(params[\"max_depth\"])\n",
    "    params[\"min_child_weight\"] = int(params[\"min_child_weight\"])\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\", # Evaluation metric\n",
    "        random_state=12345, # Reproducibility\n",
    "        tree_method=\"hist\", # Fast + recommended\n",
    "        scale_pos_weight=CLASS_WEIGHT_RATIO, #  BALANCE THE CLASSES\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_1_train, y_1_train,\n",
    "        eval_set=[(X_1_valid, y_1_valid)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Predict validation\n",
    "    y_val_pred = model.predict(X_1_valid) # Accuracy, F1, Precision, Recall, Confusion Matrix\n",
    "    y_val_proba = model.predict_proba(X_1_valid)[:, 1] # ROC-AUC (metric for Hyperopt)\n",
    "\n",
    "    val_roc = roc_auc_score(y_1_valid, y_val_proba)  # Use ROC-AUC to optimize\n",
    "\n",
    "    return {\"loss\": -val_roc, \"status\": STATUS_OK}\n",
    "\n",
    "# --- 3. Run Hyperopt Search ---\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(\n",
    "    fn=objective, # Function to minimize\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest, # Search algorithm (TPE = Tree-structured Parzen Estimator)\n",
    "    max_evals=100, # Number of different parameter sets to try\n",
    "    trials=trials, # Object to store all results\n",
    "    rstate=np.random.default_rng(42)\n",
    ")\n",
    "\n",
    "# Convert integer hyperparameters returned by Hyperopt\n",
    "best_params[\"n_estimators\"]     = int(best_params[\"n_estimators\"])\n",
    "best_params[\"max_depth\"]        = int(best_params[\"max_depth\"])\n",
    "best_params[\"min_child_weight\"] = int(best_params[\"min_child_weight\"])\n",
    "\n",
    "\n",
    "print(\"\\n Best Hyperopt Parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# --- 4. TRAIN FINAL MODEL WITH BEST PARAMETERS ---\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=12345,\n",
    "    tree_method=\"hist\",\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "xgb_clf.fit(\n",
    "    X_1_train, y_1_train,\n",
    "    eval_set=[(X_1_valid, y_1_valid)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "# VALIDATION PREDICTIONS\n",
    "y_val_pred = xgb_clf.predict(X_1_valid)\n",
    "y_val_proba = xgb_clf.predict_proba(X_1_valid)[:, 1]\n",
    "\n",
    "val_acc_2  = accuracy_score(y_1_valid, y_val_pred)\n",
    "val_roc_2  = roc_auc_score(y_1_valid, y_val_proba)\n",
    "val_prec_2 = precision_score(y_1_valid, y_val_pred)\n",
    "val_rec_2  = recall_score(y_1_valid, y_val_pred)\n",
    "val_f1_2   = f1_score(y_1_valid, y_val_pred)\n",
    "\n",
    "print(\"\\nðŸ“Š Validation Results:\")\n",
    "print(f\"Accuracy: {val_acc_2:.4f}\")\n",
    "print(f\"ROC AUC: {val_roc_2:.4f}\")\n",
    "print(f\"Precision: {val_prec_2:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {val_rec_2:.4f}\")\n",
    "print(f\"F1-Score: {val_f1_2:.4f}\")\n",
    "\n",
    "# Confusion Matrix (Validation)\n",
    "val_cm_2 = confusion_matrix(y_1_valid, y_val_pred)\n",
    "print(\"\\nðŸ”· Validation Confusion Matrix:\")\n",
    "print(\"[[True_Pos False_Pos]\")\n",
    "print(\"[False_Neg True_Neg]]\")\n",
    "print(val_cm_2)\n",
    "\n",
    "# TEST PREDICTIONS\n",
    "y_test_pred = xgb_clf.predict(X_1_test)\n",
    "y_test_proba = xgb_clf.predict_proba(X_1_test)[:, 1]\n",
    "\n",
    "test_acc_2  = accuracy_score(y_1_test, y_test_pred)\n",
    "test_roc_2  = roc_auc_score(y_1_test, y_test_proba)\n",
    "test_prec_2 = precision_score(y_1_test, y_test_pred)\n",
    "test_rec_2  = recall_score(y_1_test, y_test_pred)\n",
    "test_f1_2   = f1_score(y_1_test, y_test_pred)\n",
    "\n",
    "print(\"\\n----------------------------------------\")\n",
    "print(\"ðŸ“Š Test Results:\")\n",
    "print(f\"Accuracy: {test_acc_2:.4f}\")\n",
    "print(f\"ROC AUC: {test_roc_2:.4f}\")\n",
    "print(f\"Precision: {test_prec_2:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {test_rec_2:.4f}\")\n",
    "print(f\"F1-Score: {test_f1_2:.4f}\")\n",
    "\n",
    "# Confusion Matrix (Test)\n",
    "test_cm_2 = confusion_matrix(y_1_test, y_test_pred)\n",
    "print(\"\\nðŸ”· Test Confusion Matrix:\")\n",
    "print(\"[[True_Pos False_Pos]\")\n",
    "print(\"[False_Neg True_Neg]]\")\n",
    "print(test_cm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c11f10",
   "metadata": {},
   "source": [
    "Logging the Differents MLflow Runs inside the Created Experiment After Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f1e990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\OneDrive\\Documents\\python_virtual_env\\data_science_1\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b55b8bcf614b3d9d729f13fbcba411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGB_Class_Feat_Eng' already exists. Creating a new version of this model...\n",
      "2025/12/02 18:02:55 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB_Class_Feat_Eng, version 3\n",
      "Created version '3' of model 'XGB_Class_Feat_Eng'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run XGB_Feat_run_v3 at: http://127.0.0.1:5000/#/experiments/982562299770504179/runs/f36f2bdf2ace450e9aea103fbce7c0b6\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/982562299770504179\n",
      "âœ… Run 'XGB_Feat_run_v3' completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Logging the initial model to MLflow ---\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Sets the current active experiment to the \"XGBoost_Classification_Feat_Eng\" experiment and returns the Experiment metadata\n",
    "xgboost_experiment = mlflow.set_experiment(\"XGBoost_Classification_Feat_Eng\")\n",
    "\n",
    "# Define a run name for this iteration of training. If not set, a unique name will be auto-generated \n",
    "run_name = \"XGB_Feat_run_v3\"\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    " # Log run tags\n",
    "  mlflow.set_tag(\"model_type\", \"xgboost\")\n",
    "  mlflow.set_tag(\"feature_engineering\", \"yes\")\n",
    "  mlflow.set_tag(\"hyperopt\", \"yes\")\n",
    "  mlflow.set_tag(\"class_weighting\", \"yes\")\n",
    "  mlflow.set_tag(\"author\", \"carlos_himura\")\n",
    "\n",
    " # FIX: Log the scale_pos_weight parameter explicitly\n",
    "  mlflow.log_param(\"scale_pos_weight\", CLASS_WEIGHT_RATIO) \n",
    "\n",
    " # Log the parameters used for the model fit\n",
    "  mlflow.log_params(best_params)\n",
    "\n",
    "  # Log the metrics that were calculated during validation\n",
    "  \n",
    "  # Validation metrics\n",
    "  mlflow.log_metric(\"val_accuracy\", float(val_acc_2))\n",
    "  mlflow.log_metric(\"val_roc_auc\", float(val_roc_2))\n",
    "  mlflow.log_metric(\"val_precision\", float(val_prec_2))\n",
    "  mlflow.log_metric(\"val_recall\", float(val_rec_2))\n",
    "  mlflow.log_metric(\"val_f1_score\", float(val_f1_2))\n",
    "\n",
    "  # Test metrics\n",
    "  mlflow.log_metric(\"test_accuracy\", float(test_acc_2))\n",
    "  mlflow.log_metric(\"test_roc_auc\", float(test_roc_2))\n",
    "  mlflow.log_metric(\"test_precision\", float(test_prec_2))\n",
    "  mlflow.log_metric(\"test_recall\", float(test_rec_2))\n",
    "  mlflow.log_metric(\"test_f1_score\", float(test_f1_2))\n",
    "\n",
    "  # Validation Confusion Matrix as CSV\n",
    "  val_cm_df = pd.DataFrame(val_cm_2)\n",
    "  val_cm_df = pd.DataFrame(val_cm_2, \n",
    "                         index=[\"Pred_Pos_1 (TP-FP)\", \"Pred_Neg_0 (FN-TN)\"], \n",
    "                         columns=[\"Act_Pos_1\", \"Act_Neg_0\"])\n",
    "  val_cm_df.to_csv(\"validation_confusion_matrix.csv\")\n",
    "  mlflow.log_artifact(\"validation_confusion_matrix.csv\")\n",
    "\n",
    "  # Test Confusion Matrix as CSV\n",
    "  test_cm_df = pd.DataFrame(test_cm_2)\n",
    "  test_cm_df = pd.DataFrame(test_cm_2,\n",
    "                          index=[\"Pred_Pos_1 (TP-FP)\", \"Pred_Neg_0 (FN-TN)\"],\n",
    "                          columns=[\"Act_Pos_1\", \"Act_Neg_0\"])\n",
    "  test_cm_df.to_csv(\"test_confusion_matrix.csv\")\n",
    "  mlflow.log_artifact(\"test_confusion_matrix.csv\")\n",
    "\n",
    "  # Generate predictions for signature inference\n",
    "  y_pred = xgb_clf.predict(X_1_test)\n",
    "\n",
    "  # Create model signature and input example\n",
    "  signature = infer_signature(X_1_test, y_pred)\n",
    "  input_example = X_1_test.iloc[:5]\n",
    "\n",
    "  # Log an instance of the trained model for later use\n",
    "  mlflow.xgboost.log_model(\n",
    "        xgb_clf, \n",
    "        name=\"xgb_clf\",\n",
    "        registered_model_name=\"XGB_Class_Feat_Eng\", # If the model name doesnâ€™t exist MLflow creates it. If it already exists MLflow automatically creates a new version\n",
    "        input_example=input_example, # A small, representative example of the kind of input the model expects\n",
    "        signature=signature # Model signature describing model input and output schema\n",
    "        )\n",
    "  \n",
    "\n",
    "print(f\"âœ… Run '{run_name}' completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60dce45",
   "metadata": {},
   "source": [
    "Metrics description \n",
    "- ROC-AUC: Measures the modelâ€™s ability to distinguish between classes\n",
    "- Accuracy: Overall correctness of the model.\n",
    "- Precision: Out of all predicted positives, how many were correct?\n",
    "- Recall (Sensitivity): Out of all actual positives, how many were detected?\n",
    "- F1 Score: Balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d696b",
   "metadata": {},
   "source": [
    "Metrics and Model Conclusion:\n",
    "\n",
    "NBA Classification â€” What Metrics Should We Use to Choose the Best Model?\n",
    "- The goal is to predict whether an NBA player would score over a certain threshold (binary classification).\n",
    "- The 60/40 imbalance has been handled with class_weight.\n",
    "- It should focus on metrics that are sensitive to both False Positives and False Negatives. Keeping in mind an accuracy of 65% might just mean it predicted the majority class correctly.\n",
    "- Primary the ROC AUC: It evaluates the model's ability to distinguish between the two classes across all possible classification thresholds.\n",
    "- Secondary F1-Score: is the harmonic mean of Precision and Recall. It provides a single number that requires the model to have high scores on both.\n",
    "- Thrid Precision and Recall: Minimizing False Positives / Minimizing False Negatives.\n",
    "\n",
    "Challenge especification: The dataset includes natural variability. Well-built models\n",
    "typically achieve around 0.80 accuracy and 0.85â€“0.90 ROC-AUC without overfitting.\n",
    "\n",
    "- Conclusion about adding the balacing:\n",
    "  - Recall improve: model is now much better at detecting the minority class (your positives).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a26d8b",
   "metadata": {},
   "source": [
    "Selecting the Best Model, Parameters, and Metrics from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c4accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Name: XGB_Feat_run_v2\n",
      "Best Run ID: 638c59328a41400c8c8386e85267e6fc\n",
      "\n",
      "Best Run Summary Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cccf0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_cccf0_level0_col0\" class=\"col_heading level0 col0\" >Test Accuracy</th>\n",
       "      <th id=\"T_cccf0_level0_col1\" class=\"col_heading level0 col1\" >Test ROC-AUC</th>\n",
       "      <th id=\"T_cccf0_level0_col2\" class=\"col_heading level0 col2\" >Test Precision</th>\n",
       "      <th id=\"T_cccf0_level0_col3\" class=\"col_heading level0 col3\" >Test Recall</th>\n",
       "      <th id=\"T_cccf0_level0_col4\" class=\"col_heading level0 col4\" >Test F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_cccf0_row0_col0\" class=\"data row0 col0\" >0.851667</td>\n",
       "      <td id=\"T_cccf0_row0_col1\" class=\"data row0 col1\" >0.929431</td>\n",
       "      <td id=\"T_cccf0_row0_col2\" class=\"data row0 col2\" >0.813988</td>\n",
       "      <td id=\"T_cccf0_row0_col3\" class=\"data row0 col3\" >0.793904</td>\n",
       "      <td id=\"T_cccf0_row0_col4\" class=\"data row0 col4\" >0.803821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fda5f174d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Parameters:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_21252\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_21252_level0_col0\" class=\"col_heading level0 col0\" >Parameter</th>\n",
       "      <th id=\"T_21252_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_21252_row0_col0\" class=\"data row0 col0\" >colsample_bytree</td>\n",
       "      <td id=\"T_21252_row0_col1\" class=\"data row0 col1\" >0.9507579290048368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_21252_row1_col0\" class=\"data row1 col0\" >gamma</td>\n",
       "      <td id=\"T_21252_row1_col1\" class=\"data row1 col1\" >9.887094626323933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_21252_row2_col0\" class=\"data row2 col0\" >learning_rate</td>\n",
       "      <td id=\"T_21252_row2_col1\" class=\"data row2 col1\" >0.1371656701428185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_21252_row3_col0\" class=\"data row3 col0\" >max_depth</td>\n",
       "      <td id=\"T_21252_row3_col1\" class=\"data row3 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_21252_row4_col0\" class=\"data row4 col0\" >min_child_weight</td>\n",
       "      <td id=\"T_21252_row4_col1\" class=\"data row4 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_21252_row5_col0\" class=\"data row5 col0\" >n_estimators</td>\n",
       "      <td id=\"T_21252_row5_col1\" class=\"data row5 col1\" >1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_21252_row6_col0\" class=\"data row6 col0\" >scale_pos_weight</td>\n",
       "      <td id=\"T_21252_row6_col1\" class=\"data row6 col1\" >1.4680073126142597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_21252_row7_col0\" class=\"data row7 col0\" >subsample</td>\n",
       "      <td id=\"T_21252_row7_col1\" class=\"data row7 col1\" >0.8702299683381548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fda5f174d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"XGBoost_Classification_Feat_Eng\")\n",
    "\n",
    "# Fetch all runs for the experiment\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    # order_by=[\"metrics.test_roc_auc DESC\"],  # Sort by best test ROC-AUC\n",
    "    order_by=[\"metrics.test_roc_auc DESC\", \"metrics.test_accuracy DESC\"],  # Sort by best test ROC-AUC and Accuracy\n",
    ")\n",
    "\n",
    "# Select the best run (first in the sorted list)\n",
    "best_run = runs[0]\n",
    "print(f\"Best Run Name: {best_run.info.run_name}\")\n",
    "print(f\"Best Run ID: {best_run.info.run_id}\")\n",
    "\n",
    "summary_data = {\n",
    "    \"Test Accuracy\": [best_run.data.metrics.get(\"test_accuracy\")],\n",
    "    \"Test ROC-AUC\": [best_run.data.metrics.get(\"test_roc_auc\")],\n",
    "    \"Test Precision\": [best_run.data.metrics.get(\"test_precision\")],\n",
    "    \"Test Recall\": [best_run.data.metrics.get(\"test_recall\")],\n",
    "    \"Test F1-Score\": [best_run.data.metrics.get(\"test_f1_score\")],\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame for a clean table\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display neatly\n",
    "print(\"\\nBest Run Summary Metrics:\")\n",
    "display(summary_df.style.hide(axis=\"index\"))\n",
    "\n",
    "# Extract best run parameters\n",
    "params_data = best_run.data.params\n",
    "\n",
    "# Convert to a DataFrame\n",
    "params_df = pd.DataFrame(list(params_data.items()), columns=[\"Parameter\", \"Value\"])\n",
    "\n",
    "# Display nicely without index\n",
    "print(\"Best Run Parameters:\")\n",
    "display(params_df.style.hide(axis=\"index\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data_science_1)",
   "language": "python",
   "name": "data_science_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
