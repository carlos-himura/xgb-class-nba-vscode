{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb247bc",
   "metadata": {},
   "source": [
    "Traning, and Experiments without Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "409f8179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>minutes_played</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>assists</th>\n",
       "      <th>steals</th>\n",
       "      <th>blocks</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>three_pct</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>plus_minus</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>rest_days</th>\n",
       "      <th>target</th>\n",
       "      <th>position_PF</th>\n",
       "      <th>position_PG</th>\n",
       "      <th>position_SF</th>\n",
       "      <th>position_SG</th>\n",
       "      <th>team_BKN</th>\n",
       "      <th>team_BOS</th>\n",
       "      <th>team_CHA</th>\n",
       "      <th>team_CHI</th>\n",
       "      <th>team_CLE</th>\n",
       "      <th>team_DAL</th>\n",
       "      <th>team_DEN</th>\n",
       "      <th>team_DET</th>\n",
       "      <th>team_GSW</th>\n",
       "      <th>team_HOU</th>\n",
       "      <th>team_IND</th>\n",
       "      <th>team_LAC</th>\n",
       "      <th>team_LAL</th>\n",
       "      <th>team_MEM</th>\n",
       "      <th>team_MIA</th>\n",
       "      <th>team_MIL</th>\n",
       "      <th>team_MIN</th>\n",
       "      <th>team_NOP</th>\n",
       "      <th>team_NYK</th>\n",
       "      <th>team_OKC</th>\n",
       "      <th>team_ORL</th>\n",
       "      <th>team_PHI</th>\n",
       "      <th>team_PHX</th>\n",
       "      <th>team_POR</th>\n",
       "      <th>team_SAC</th>\n",
       "      <th>team_SAS</th>\n",
       "      <th>team_TOR</th>\n",
       "      <th>team_UTA</th>\n",
       "      <th>team_WAS</th>\n",
       "      <th>opponent_BKN</th>\n",
       "      <th>opponent_BOS</th>\n",
       "      <th>opponent_CHA</th>\n",
       "      <th>opponent_CHI</th>\n",
       "      <th>opponent_CLE</th>\n",
       "      <th>opponent_DAL</th>\n",
       "      <th>opponent_DEN</th>\n",
       "      <th>opponent_DET</th>\n",
       "      <th>opponent_GSW</th>\n",
       "      <th>opponent_HOU</th>\n",
       "      <th>opponent_IND</th>\n",
       "      <th>opponent_LAC</th>\n",
       "      <th>opponent_LAL</th>\n",
       "      <th>opponent_MEM</th>\n",
       "      <th>opponent_MIA</th>\n",
       "      <th>opponent_MIL</th>\n",
       "      <th>opponent_MIN</th>\n",
       "      <th>opponent_NOP</th>\n",
       "      <th>opponent_NYK</th>\n",
       "      <th>opponent_OKC</th>\n",
       "      <th>opponent_ORL</th>\n",
       "      <th>opponent_PHI</th>\n",
       "      <th>opponent_PHX</th>\n",
       "      <th>opponent_POR</th>\n",
       "      <th>opponent_SAC</th>\n",
       "      <th>opponent_SAS</th>\n",
       "      <th>opponent_TOR</th>\n",
       "      <th>opponent_UTA</th>\n",
       "      <th>opponent_WAS</th>\n",
       "      <th>game_location_Home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>12.2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>51.4</td>\n",
       "      <td>19.6</td>\n",
       "      <td>79.9</td>\n",
       "      <td>-3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>30.9</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>68.1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>18.9</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>47.4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>-2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>49.3</td>\n",
       "      <td>45.8</td>\n",
       "      <td>68.1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>27.8</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  minutes_played  points  rebounds  assists  steals  blocks  turnovers  \\\n",
       "0   25            12.2       9         3        0       1       1          2   \n",
       "1   25            30.9      15        14        5       1       2          0   \n",
       "2   30            18.9      11         4        2       1       0          2   \n",
       "3   27            20.0      12         4        2       0       0          3   \n",
       "4   29            27.8      16        10        4       1       0          2   \n",
       "\n",
       "   fg_pct  three_pct  ft_pct  plus_minus  efficiency  rest_days  target  \\\n",
       "0    51.4       19.6    79.9          -3          12          2       0   \n",
       "1    41.0       31.2    68.1           1          37          1       1   \n",
       "2    47.4       28.0    78.2          -2          16          2       0   \n",
       "3    49.3       45.8    68.1           7          15          2       0   \n",
       "4    34.5       22.5    76.0           7          29          1       1   \n",
       "\n",
       "   position_PF  position_PG  position_SF  position_SG  team_BKN  team_BOS  \\\n",
       "0            0            0            0            0         0         0   \n",
       "1            0            0            0            0         0         0   \n",
       "2            1            0            0            0         0         0   \n",
       "3            0            0            0            1         0         0   \n",
       "4            0            0            0            0         0         0   \n",
       "\n",
       "   team_CHA  team_CHI  team_CLE  team_DAL  team_DEN  team_DET  team_GSW  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   team_HOU  team_IND  team_LAC  team_LAL  team_MEM  team_MIA  team_MIL  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   team_MIN  team_NOP  team_NYK  team_OKC  team_ORL  team_PHI  team_PHX  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         1         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         1         0   \n",
       "\n",
       "   team_POR  team_SAC  team_SAS  team_TOR  team_UTA  team_WAS  opponent_BKN  \\\n",
       "0         0         0         0         0         0         0             0   \n",
       "1         0         0         0         0         0         0             0   \n",
       "2         0         0         0         0         0         0             0   \n",
       "3         0         0         1         0         0         0             0   \n",
       "4         0         0         0         0         0         0             0   \n",
       "\n",
       "   opponent_BOS  opponent_CHA  opponent_CHI  opponent_CLE  opponent_DAL  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   opponent_DEN  opponent_DET  opponent_GSW  opponent_HOU  opponent_IND  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             1             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   opponent_LAC  opponent_LAL  opponent_MEM  opponent_MIA  opponent_MIL  \\\n",
       "0             0             0             0             1             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   opponent_MIN  opponent_NOP  opponent_NYK  opponent_OKC  opponent_ORL  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             1             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             1   \n",
       "\n",
       "   opponent_PHI  opponent_PHX  opponent_POR  opponent_SAC  opponent_SAS  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   opponent_TOR  opponent_UTA  opponent_WAS  game_location_Home  \n",
       "0             0             0             0                   1  \n",
       "1             0             0             0                   0  \n",
       "2             0             0             0                   0  \n",
       "3             0             0             1                   0  \n",
       "4             0             0             0                   0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First experiment without including feature engineering\n",
    "\n",
    "import pandas as pd\n",
    "df_preprocessed = pd.read_csv('Datasets/ds_preprocessed.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24003a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Rows: 5400 -  Validation set Rows: 1800 -  Test set Rows: 1800\n"
     ]
    }
   ],
   "source": [
    "# Test split for the experiment without feature engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Defining features and target\n",
    "X_1 = df_preprocessed.drop(columns='target')\n",
    "y_1 = df_preprocessed['target']\n",
    "\n",
    "# Test Split (20% of total data)\n",
    "X_1_train_valid, X_1_test, y_1_train_valid, y_1_test = train_test_split(\n",
    "    X_1, y_1, test_size=0.2, random_state=12345\n",
    ")\n",
    "\n",
    "# Validation split (25% of the remaining 80% â†’ 20% of total)\n",
    "X_1_train, X_1_valid, y_1_train, y_1_valid = train_test_split(\n",
    "    X_1_train_valid, y_1_train_valid, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Training set Rows: {X_1_train.shape[0]} - \",\n",
    "    f\"Validation set Rows: {X_1_valid.shape[0]} - \",\n",
    "    f\"Test set Rows: {X_1_test.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88024cd",
   "metadata": {},
   "source": [
    "Checking Class Balance in the Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559bf204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts\n",
      "target\n",
      "0    3212\n",
      "1    2188\n",
      "Name: count, dtype: int64\n",
      "class Proportions\n",
      "target\n",
      "0    0.594815\n",
      "1    0.405185\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_train is a Pandas Series\n",
    "# The primary reason for checking the class balance is to prevent the model from being biased toward the majority class.\n",
    "class_counts = y_1_train.value_counts()\n",
    "print(\"class counts\")\n",
    "print(class_counts)\n",
    "\n",
    "class_proportions = y_1_train.value_counts(normalize=True)\n",
    "print(\"class Proportions\")\n",
    "print(class_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453e5bc",
   "metadata": {},
   "source": [
    "Class Balance Conclusion:\n",
    "- The dataset has a ~60/40 split between the two classes.\n",
    "- Is this imbalanced? Yes, it is imbalanced because the classes are not equal (50/50).\n",
    "- Is it severely imbalanced? No. A severe imbalance is usually considered to be anything worse than 80/20 or 90/10.\n",
    "\n",
    "Implications:\n",
    "- It is manageable, but it still requires attention when predicting the minority class.\n",
    "- Better to use the Precision, Recall, F1-Score, and ROC AUC. To check how well perform with the minority class.\n",
    "- Adjust class weighting: for XGB set the \"scale_pos_weight\" parameter. Starting value is the ratio of negative to positive samples 3212/2188 = 1.47. It tells the model to give the monority class 1.47 times the importance of the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e5a29",
   "metadata": {},
   "source": [
    "First Model Training with Initial Parameters (no Hyperopt) and without Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bccc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Validation Results:\n",
      "Accuracy: 0.8444\n",
      "ROC AUC: 0.9243\n",
      "Precision: 0.7926\n",
      "Recall (Sensitivity): 0.8299\n",
      "F1-Score: 0.8108\n",
      "\n",
      "ðŸ”· Validation Confusion Matrix:\n",
      "[[True_Pos False_Pos]\n",
      "[False_Neg True_Neg]]\n",
      "[[920 157]\n",
      " [123 600]]\n",
      "\n",
      "----------------------------------------\n",
      "ðŸ“Š Test Results:\n",
      "Accuracy: 0.8367\n",
      "ROC AUC: 0.9230\n",
      "Precision: 0.7786\n",
      "Recall (Sensitivity): 0.8012\n",
      "F1-Score: 0.7897\n",
      "\n",
      "ðŸ”· Test Confusion Matrix:\n",
      "[[True_Pos False_Pos]\n",
      "[False_Neg True_Neg]]\n",
      "[[954 157]\n",
      " [137 552]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "CLASS_WEIGHT_RATIO = 3212 / 2188 # 0 class / 1 class\n",
    "\n",
    "# Initial XGBoost Classification Parameters\n",
    "initial_clf_params = {\n",
    "    'n_estimators': 200,          # Number of trees\n",
    "    'max_depth': 5,               # Maximum depth of each tree\n",
    "    'learning_rate': 0.1,         # Boosting learning rate\n",
    "    'subsample': 0.8,             # % of rows sampled per tree\n",
    "    'colsample_bytree': 0.8,      # % of features sampled per tree\n",
    "    'objective': 'binary:logistic', # binary classification funtion loss\n",
    "    'eval_metric': 'logloss',     # binary cross-entropy loss\n",
    "    'random_state': 12345,        # Reproducibility\n",
    "    'tree_method': 'hist',         # Histogram-based Tree Construction Algorithm: Fast + recommended (Perfect for Sagemaker)\n",
    "    'scale_pos_weight': CLASS_WEIGHT_RATIO     # Adjust Class Weighting\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb_clf = XGBClassifier(**initial_clf_params)\n",
    "\n",
    "# Train the model\n",
    "xgb_clf.fit(\n",
    "    X_1_train, y_1_train,\n",
    "    eval_set=[(X_1_valid, y_1_valid)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# VALIDATION PREDICTIONS\n",
    "# -------------------------\n",
    "y_val_pred = xgb_clf.predict(X_1_valid) # compute metrics that need discrete labels: accuracy, precision, recall, F1-score, confusion matrix, etc (Ratios)\n",
    "y_val_proba = xgb_clf.predict_proba(X_1_valid)[:, 1] # probability of the positive class (used for ROC-AUC and any thresholding decisions)\n",
    "\n",
    "val_acc  = accuracy_score(y_1_valid, y_val_pred)  # Fraction of correct predictions\n",
    "val_roc  = roc_auc_score(y_1_valid, y_val_proba)  # Measures the modelâ€™s ability to distinguish between classes\n",
    "val_prec = precision_score(y_1_valid, y_val_pred) # Fraction of true positives among predicted positives\n",
    "val_rec  = recall_score(y_1_valid, y_val_pred)    # Fraction of true positives among actual positives\n",
    "val_f1   = f1_score(y_1_valid, y_val_pred)        # Harmonic mean of precision and recall\n",
    "\n",
    "print(\"\\nðŸ“Š Validation Results:\")\n",
    "print(f\"Accuracy: {val_acc:.4f}\")\n",
    "print(f\"ROC AUC: {val_roc:.4f}\")\n",
    "print(f\"Precision: {val_prec:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {val_rec:.4f}\")\n",
    "print(f\"F1-Score: {val_f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix (Validation)\n",
    "val_cm_1 = confusion_matrix(y_1_valid, y_val_pred)\n",
    "print(\"\\nðŸ”· Validation Confusion Matrix:\")\n",
    "print(\"[[True_Pos False_Pos]\") \n",
    "print(\"[False_Neg True_Neg]]\")\n",
    "print(val_cm_1)\n",
    "\n",
    "# --------------------\n",
    "# TEST PREDICTIONS\n",
    "# --------------------\n",
    "y_test_pred = xgb_clf.predict(X_1_test) # compute metrics that need discrete labels: accuracy, precision, recall, F1-score, confusion matrix, etc (Ratios)\n",
    "y_test_proba = xgb_clf.predict_proba(X_1_test)[:, 1] # probability of the positive class (used for ROC-AUC and any thresholding decisions)\n",
    "\n",
    "test_acc  = accuracy_score(y_1_test, y_test_pred)  # Fraction of correct predictions\n",
    "test_roc  = roc_auc_score(y_1_test, y_test_proba)  # Measures the modelâ€™s ability to distinguish between classes\n",
    "test_prec = precision_score(y_1_test, y_test_pred) # Fraction of true positives among predicted positives\n",
    "test_rec  = recall_score(y_1_test, y_test_pred)    # Fraction of true positives among actual positives\n",
    "test_f1   = f1_score(y_1_test, y_test_pred)        # Harmonic mean of precision and recall   \n",
    "\n",
    "print(\"\\n----------------------------------------\")\n",
    "print(\"ðŸ“Š Test Results:\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"ROC AUC: {test_roc:.4f}\")\n",
    "print(f\"Precision: {test_prec:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {test_rec:.4f}\")\n",
    "print(f\"F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix (Test)\n",
    "test_cm_1 = confusion_matrix(y_1_test, y_test_pred)\n",
    "print(\"\\nðŸ”· Test Confusion Matrix:\")\n",
    "print(\"[[True_Pos False_Pos]\")\n",
    "print(\"[False_Neg True_Neg]]\")\n",
    "print(test_cm_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f062d0a",
   "metadata": {},
   "source": [
    "MLflow Experiment Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c3f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching by Experiment Tag - Project Name:\n",
      "<Experiment: artifact_location='mlflow-artifacts:/463662006620502774', creation_time=1764682857567, experiment_id='463662006620502774', last_update_time=1764682857567, lifecycle_stage='active', name='XGBoost_Classification_No_Feat_Eng', tags={'mlflow.note.content': 'This is the WZ challenge about NBA player '\n",
      "                        'performanceThis experiment contains an XGBoost model '\n",
      "                        'with hyperparameter tuning using Hyperopt.',\n",
      " 'project_manager': 'carlos_himura',\n",
      " 'project_name': 'nba_binary_classification',\n",
      " 'team': 'data_science'}>\n"
     ]
    }
   ],
   "source": [
    "# --- Create MLflow Experiment ---\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000/\")\n",
    "\n",
    "# Set up MLflow experiment\n",
    "experiment_description = (\n",
    "    \"This is the WZ challenge about NBA player performance\"\n",
    "    \"This experiment contains an XGBoost model with hyperparameter tuning using Hyperopt.\"\n",
    ")\n",
    "experiment_tags = {\n",
    "    \"team\": \"data_science\",\n",
    "    \"project_manager\": \"carlos_himura\",\n",
    "    \"project_name\": \"nba_binary_classification\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "experiment_name = \"XGBoost_Classification_No_Feat_Eng\"\n",
    "xgboost_experiment = client.create_experiment(name = experiment_name, tags = experiment_tags)\n",
    "\n",
    "search_experiment = client.search_experiments(\n",
    "  filter_string=\"tags.`project_name` = 'nba_binary_classification'\"\n",
    ")\n",
    "print(\"Searching by Experiment Tag - Project Name:\")\n",
    "print(search_experiment[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e89c07",
   "metadata": {},
   "source": [
    "Logging the Initial MLflow Run inside the Created Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d229269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\OneDrive\\Documents\\python_virtual_env\\data_science_1\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6583fc2135d544f0bb93b94769f7d884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGB_Class_No_Feat_Eng' already exists. Creating a new version of this model...\n",
      "2025/12/02 14:50:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB_Class_No_Feat_Eng, version 4\n",
      "Created version '4' of model 'XGB_Class_No_Feat_Eng'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run XGB_No_Feat_run_v5 at: http://127.0.0.1:5000/#/experiments/463662006620502774/runs/855beea0acf54ed6b945b70efdb5e53b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/463662006620502774\n",
      "âœ… Run 'XGB_No_Feat_run_v5' completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Logging the initial model to MLflow ---\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Sets the current active experiment to the \"XGBoost_Classification_No_Feat_Eng\" experiment and returns the Experiment metadata\n",
    "xgboost_experiment = mlflow.set_experiment(\"XGBoost_Classification_No_Feat_Eng\")\n",
    "\n",
    "# Define a run name for this iteration of training. If not set, a unique name will be auto-generated \n",
    "run_name = \"XGB_No_Feat_run_v5\"\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    " # Log run tags\n",
    "  mlflow.set_tag(\"model_type\", \"xgboost\")\n",
    "  mlflow.set_tag(\"feature_engineering\", \"none\")\n",
    "  mlflow.set_tag(\"hyperopt\", \"none\")\n",
    "  mlflow.set_tag(\"class_weighting\", \"yes\")\n",
    "  mlflow.set_tag(\"author\", \"carlos_himura\")\n",
    "\n",
    " # Log the parameters used for the model fit\n",
    "  mlflow.log_params(initial_clf_params)\n",
    "\n",
    "  # Log the metrics that were calculated during validation\n",
    "  \n",
    "  # Validation metrics\n",
    "  mlflow.log_metric(\"val_accuracy\", float(val_acc))\n",
    "  mlflow.log_metric(\"val_roc_auc\", float(val_roc))\n",
    "  mlflow.log_metric(\"val_precision\", float(val_prec))\n",
    "  mlflow.log_metric(\"val_recall\", float(val_rec))\n",
    "  mlflow.log_metric(\"val_f1_score\", float(val_f1))\n",
    "\n",
    "  # Test metrics\n",
    "  mlflow.log_metric(\"test_accuracy\", float(test_acc))\n",
    "  mlflow.log_metric(\"test_roc_auc\", float(test_roc))\n",
    "  mlflow.log_metric(\"test_precision\", float(test_prec))\n",
    "  mlflow.log_metric(\"test_recall\", float(test_rec))\n",
    "  mlflow.log_metric(\"test_f1_score\", float(test_f1))\n",
    "\n",
    " # Validation Confusion Matrix as CSV\n",
    "  val_cm_df = pd.DataFrame(val_cm_1)\n",
    "  val_cm_df = pd.DataFrame(val_cm_1, \n",
    "                         index=[\"Pred_Pos_1 (TP-FP)\", \"Pred_Neg_0 (FN-TN)\"], \n",
    "                         columns=[\"Act_Pos_1\", \"Act_Neg_0\"])\n",
    "  val_cm_df.to_csv(\"validation_confusion_matrix.csv\")\n",
    "  mlflow.log_artifact(\"validation_confusion_matrix.csv\")\n",
    "\n",
    "  # Test Confusion Matrix as CSV\n",
    "  test_cm_df = pd.DataFrame(test_cm_1)\n",
    "  test_cm_df = pd.DataFrame(test_cm_1,\n",
    "                          index=[\"Pred_Pos_1 (TP-FP)\", \"Pred_Neg_0 (FN-TN)\"],\n",
    "                          columns=[\"Act_Pos_1\", \"Act_Neg_0\"])\n",
    "  test_cm_df.to_csv(\"test_confusion_matrix.csv\")\n",
    "  mlflow.log_artifact(\"test_confusion_matrix.csv\")\n",
    "\n",
    "  # Generate predictions for signature inference\n",
    "  y_pred = xgb_clf.predict(X_1_test)\n",
    "\n",
    "  # Create model signature and input example\n",
    "  signature = infer_signature(X_1_test, y_pred)\n",
    "  input_example = X_1_test.iloc[:5]\n",
    "\n",
    "  # Log an instance of the trained model for later use\n",
    "  mlflow.xgboost.log_model(\n",
    "        xgb_clf, \n",
    "        name=\"xgb_clf\",\n",
    "        registered_model_name=\"XGB_Class_No_Feat_Eng\", # If the model name doesnâ€™t exist MLflow creates it. If it already exists MLflow automatically creates a new version\n",
    "        input_example=input_example, # A small, representative example of the kind of input the model expects\n",
    "        signature=signature # Model signature describing model input and output schema\n",
    "        )\n",
    "  \n",
    "\n",
    "print(f\"âœ… Run '{run_name}' completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5e88b",
   "metadata": {},
   "source": [
    "Second Model Training with Hyperopt and without Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7fe70",
   "metadata": {},
   "source": [
    "Why Hyperopt?\n",
    "- Performs automated hyperparameter tuning using intelligent search algorithms like Bayesian Optimization / TPE.\n",
    "- Instead of trying random values blindly, Bayesian Optimization learns from previous trials and chooses better hyperparameters over time.\n",
    "\n",
    "How is it work?\n",
    "1. Search space = ingredients + allowed amounts --- Tell Hyperopt what values it can try\n",
    "2. Objective function = taste test score --- Hyperopt tests a parameter set and gets a score\n",
    "3. TPE algorithm = learns which combinations taste good --- Hyperopt runs Bayesian optimization (TPE) to find the best params\n",
    "4. Final model = your final perfect dish --- Use best params on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5dc9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\OneDrive\\Documents\\python_virtual_env\\data_science_1\\Lib\\site-packages\\hyperopt\\atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:27<00:00,  1.10trial/s, best loss: -0.9310568905224416]\n",
      "\n",
      " Best Hyperopt Parameters:\n",
      "{'colsample_bytree': np.float64(0.9806881870543972), 'gamma': np.float64(3.94634986154594), 'learning_rate': np.float64(0.045974998070504425), 'max_depth': 3, 'min_child_weight': 10, 'n_estimators': 250, 'subsample': np.float64(0.8320612810134949)}\n",
      "\n",
      "ðŸ“Š Validation Results:\n",
      "Accuracy: 0.8528\n",
      "ROC AUC: 0.9315\n",
      "Precision: 0.8225\n",
      "Recall (Sensitivity): 0.8077\n",
      "F1-Score: 0.8151\n",
      "\n",
      "ðŸ”· Validation Confusion Matrix:\n",
      "[[True_Pos False_Pos]\n",
      "[False_Neg True_Neg]]\n",
      "[[951 126]\n",
      " [139 584]]\n",
      "\n",
      "----------------------------------------\n",
      "ðŸ“Š Test Results:\n",
      "Accuracy: 0.8478\n",
      "ROC AUC: 0.9302\n",
      "Precision: 0.8092\n",
      "Recall (Sensitivity): 0.7881\n",
      "F1-Score: 0.7985\n",
      "\n",
      "ðŸ”· Test Confusion Matrix:\n",
      "[[True_Pos False_Pos]\n",
      "[False_Neg True_Neg]]\n",
      "[[983 128]\n",
      " [146 543]]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# The ratio for scale_pos_weight is calculated from your class counts (3212 / 2188)\n",
    "CLASS_WEIGHT_RATIO = 3212 / 2188 # 0 Class / 1 Class\n",
    "\n",
    "# --- 1. Define the Search Space ---\n",
    "# Defining the range of values that Hyperopt will test for each hyperparameter.\n",
    "# Using the defaults as a guide to create the ranges.\n",
    "\n",
    "search_space = {\n",
    "    \"n_estimators\":     hp.quniform(\"n_estimators\", 100, 600, 25), # Number of trees\n",
    "    \"max_depth\":        hp.quniform(\"max_depth\", 3, 10, 1), # Maximum depth of each tree\n",
    "    \"learning_rate\":    hp.loguniform(\"learning_rate\", np.log(0.01), np.log(0.3)), # Boosting learning rate\n",
    "    \"subsample\":        hp.uniform(\"subsample\", 0.6, 1.0), # % of rows sampled per tree\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.6, 1.0), # % of features sampled per tree\n",
    "    \"gamma\":            hp.uniform(\"gamma\", 0, 5), # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    \"min_child_weight\": hp.quniform(\"min_child_weight\", 1, 10, 1), # It acts as a regularization term to prevent the model from learning relationships that are too specific to the training data\n",
    "}\n",
    "\n",
    "# --- 2. Define the objective function ---\n",
    "def objective(params):\n",
    "\n",
    "    # Convert integer params\n",
    "    params[\"n_estimators\"]     = int(params[\"n_estimators\"])\n",
    "    params[\"max_depth\"]        = int(params[\"max_depth\"])\n",
    "    params[\"min_child_weight\"] = int(params[\"min_child_weight\"])\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        objective=\"binary:logistic\", # binary classification funtion loss\n",
    "        eval_metric=\"logloss\", # Evaluation metric\n",
    "        random_state=12345, # Reproducibility\n",
    "        tree_method=\"hist\", # Fast + recommended\n",
    "        scale_pos_weight=CLASS_WEIGHT_RATIO, # BALANCE THE CLASSES\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_1_train, y_1_train,\n",
    "        eval_set=[(X_1_valid, y_1_valid)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Predict validation\n",
    "    y_val_pred = model.predict(X_1_valid) # compute metrics that need discrete labels: accuracy, precision, recall, F1-score, confusion matrix, etc (Ratios)\n",
    "    y_val_proba = model.predict_proba(X_1_valid)[:, 1] # probability of the positive class (used for ROC-AUC and any thresholding decisions)\n",
    "\n",
    "    val_roc = roc_auc_score(y_1_valid, y_val_proba)  # Use ROC-AUC to optimize\n",
    "\n",
    "    return {\"loss\": -val_roc, \"status\": STATUS_OK}\n",
    "\n",
    "# --- 3. Run Hyperopt Search ---\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(\n",
    "    fn=objective, # Function to minimize\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest, # Search algorithm (TPE = Tree-structured Parzen Estimator)\n",
    "    max_evals=30, # Number of different parameter sets to try\n",
    "    trials=trials, # Object to store all results\n",
    "    rstate=np.random.default_rng(42)\n",
    ")\n",
    "\n",
    "# Convert integer hyperparameters returned by Hyperopt\n",
    "best_params[\"n_estimators\"]     = int(best_params[\"n_estimators\"])\n",
    "best_params[\"max_depth\"]        = int(best_params[\"max_depth\"])\n",
    "best_params[\"min_child_weight\"] = int(best_params[\"min_child_weight\"])\n",
    "\n",
    "\n",
    "print(\"\\n Best Hyperopt Parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# --- 4. TRAIN FINAL MODEL WITH BEST PARAMETERS ---\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=12345,\n",
    "    tree_method=\"hist\",\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "xgb_clf.fit(\n",
    "    X_1_train, y_1_train,\n",
    "    eval_set=[(X_1_valid, y_1_valid)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "# VALIDATION PREDICTIONS\n",
    "y_val_pred = xgb_clf.predict(X_1_valid) # compute metrics that need discrete labels: accuracy, precision, recall, F1-score, confusion matrix, etc (Ratios)\n",
    "y_val_proba = xgb_clf.predict_proba(X_1_valid)[:, 1] # probability of the positive class (used for ROC-AUC and any thresholding decisions)\n",
    "\n",
    "val_acc_2  = accuracy_score(y_1_valid, y_val_pred) # Fraction of correct predictions\n",
    "val_roc_2  = roc_auc_score(y_1_valid, y_val_proba) # Measures the modelâ€™s ability to distinguish between classes \n",
    "val_prec_2 = precision_score(y_1_valid, y_val_pred) # Fraction of true positives among predicted positives\n",
    "val_rec_2  = recall_score(y_1_valid, y_val_pred) # Fraction of true positives among actual positives\n",
    "val_f1_2   = f1_score(y_1_valid, y_val_pred)  # Harmonic mean of precision and recall\n",
    "\n",
    "print(\"\\nðŸ“Š Validation Results:\")\n",
    "print(f\"Accuracy: {val_acc_2:.4f}\")\n",
    "print(f\"ROC AUC: {val_roc_2:.4f}\")\n",
    "print(f\"Precision: {val_prec_2:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {val_rec_2:.4f}\")\n",
    "print(f\"F1-Score: {val_f1_2:.4f}\")\n",
    "\n",
    "# Confusion Matrix (Validation)\n",
    "val_cm_2 = confusion_matrix(y_1_valid, y_val_pred)\n",
    "print(\"\\nðŸ”· Validation Confusion Matrix:\")\n",
    "print(\"[[True_Pos False_Pos]\")\n",
    "print(\"[False_Neg True_Neg]]\")\n",
    "print(val_cm_2)\n",
    "\n",
    "# TEST PREDICTIONS\n",
    "y_test_pred = xgb_clf.predict(X_1_test) # compute metrics that need discrete labels: accuracy, precision, recall, F1-score, confusion matrix, etc (Ratios)\n",
    "y_test_proba = xgb_clf.predict_proba(X_1_test)[:, 1] # probability of the positive class (used for ROC-AUC and any thresholding decisions)\n",
    "\n",
    "test_acc_2  = accuracy_score(y_1_test, y_test_pred) # Fraction of correct predictions\n",
    "test_roc_2  = roc_auc_score(y_1_test, y_test_proba) # Measures the modelâ€™s ability to distinguish between classes\n",
    "test_prec_2 = precision_score(y_1_test, y_test_pred) # Fraction of true positives among predicted positives\n",
    "test_rec_2  = recall_score(y_1_test, y_test_pred) # Fraction of true positives among actual positives\n",
    "test_f1_2   = f1_score(y_1_test, y_test_pred) # Harmonic mean of precision and recall\n",
    "\n",
    "print(\"\\n----------------------------------------\")\n",
    "print(\"ðŸ“Š Test Results:\")\n",
    "print(f\"Accuracy: {test_acc_2:.4f}\")\n",
    "print(f\"ROC AUC: {test_roc_2:.4f}\")\n",
    "print(f\"Precision: {test_prec_2:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {test_rec_2:.4f}\")\n",
    "print(f\"F1-Score: {test_f1_2:.4f}\")\n",
    "\n",
    "# Confusion Matrix (Test)\n",
    "test_cm_2 = confusion_matrix(y_1_test, y_test_pred)\n",
    "print(\"\\nðŸ”· Test Confusion Matrix:\")\n",
    "print(\"[[True_Pos False_Pos]\")\n",
    "print(\"[False_Neg True_Neg]]\")\n",
    "print(test_cm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c11f10",
   "metadata": {},
   "source": [
    "Logging the Differents MLflow Runs inside the Created Experiment After Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35f1e990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\OneDrive\\Documents\\python_virtual_env\\data_science_1\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89594c02e8be4e14abb3eee0d7952a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGB_Class_No_Feat_Eng' already exists. Creating a new version of this model...\n",
      "2025/12/02 15:11:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB_Class_No_Feat_Eng, version 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run XGB_No_Feat_run_v6 at: http://127.0.0.1:5000/#/experiments/463662006620502774/runs/7f161a3cd2bc463caa09d8ddb42af2df\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/463662006620502774\n",
      "âœ… Run 'XGB_No_Feat_run_v6' completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '5' of model 'XGB_Class_No_Feat_Eng'.\n"
     ]
    }
   ],
   "source": [
    "# --- Logging the initial model to MLflow ---\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Sets the current active experiment to the \"XGBoost_Classification_No_Feat_Eng\" experiment and returns the Experiment metadata\n",
    "xgboost_experiment = mlflow.set_experiment(\"XGBoost_Classification_No_Feat_Eng\")\n",
    "\n",
    "# Define a run name for this iteration of training. If not set, a unique name will be auto-generated \n",
    "run_name = \"XGB_No_Feat_run_v6\"\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    " # Log run tags\n",
    "  mlflow.set_tag(\"model_type\", \"xgboost\")\n",
    "  mlflow.set_tag(\"feature_engineering\", \"none\")\n",
    "  mlflow.set_tag(\"hyperopt\", \"yes\")\n",
    "  mlflow.set_tag(\"class_weighting\", \"yes\")\n",
    "  mlflow.set_tag(\"author\", \"carlos_himura\")\n",
    "\n",
    " # FIX: Log the scale_pos_weight parameter explicitly\n",
    "  mlflow.log_param(\"scale_pos_weight\", CLASS_WEIGHT_RATIO) \n",
    "\n",
    " # Log the parameters used for the model fit\n",
    "  mlflow.log_params(best_params)\n",
    "\n",
    "  # Log the metrics that were calculated during validation\n",
    "  \n",
    "  # Validation metrics\n",
    "  mlflow.log_metric(\"val_accuracy\", float(val_acc_2))\n",
    "  mlflow.log_metric(\"val_roc_auc\", float(val_roc_2))\n",
    "  mlflow.log_metric(\"val_precision\", float(val_prec_2))\n",
    "  mlflow.log_metric(\"val_recall\", float(val_rec_2))\n",
    "  mlflow.log_metric(\"val_f1_score\", float(val_f1_2))\n",
    "\n",
    "  # Test metrics\n",
    "  mlflow.log_metric(\"test_accuracy\", float(test_acc_2))\n",
    "  mlflow.log_metric(\"test_roc_auc\", float(test_roc_2))\n",
    "  mlflow.log_metric(\"test_precision\", float(test_prec_2))\n",
    "  mlflow.log_metric(\"test_recall\", float(test_rec_2))\n",
    "  mlflow.log_metric(\"test_f1_score\", float(test_f1_2))\n",
    "\n",
    "  # Validation Confusion Matrix as CSV\n",
    "  val_cm_df = pd.DataFrame(val_cm_2)\n",
    "  val_cm_df = pd.DataFrame(val_cm_2, \n",
    "                         index=[\"Pred_Pos_1 (TP-FP)\", \"Pred_Neg_0 (FN-TN)\"], \n",
    "                         columns=[\"Act_Pos_1\", \"Act_Neg_0\"])\n",
    "  val_cm_df.to_csv(\"validation_confusion_matrix.csv\")\n",
    "  mlflow.log_artifact(\"validation_confusion_matrix.csv\")\n",
    "\n",
    "  # Test Confusion Matrix as CSV\n",
    "  test_cm_df = pd.DataFrame(test_cm_2)\n",
    "  test_cm_df = pd.DataFrame(test_cm_2,\n",
    "                          index=[\"Pred_Pos_1 (TP-FP)\", \"Pred_Neg_0 (FN-TN)\"],\n",
    "                          columns=[\"Act_Pos_1\", \"Act_Neg_0\"])\n",
    "  test_cm_df.to_csv(\"test_confusion_matrix.csv\")\n",
    "  mlflow.log_artifact(\"test_confusion_matrix.csv\")\n",
    "\n",
    "  # Generate predictions for signature inference\n",
    "  y_pred = xgb_clf.predict(X_1_test)\n",
    "\n",
    "  # Create model signature and input example\n",
    "  signature = infer_signature(X_1_test, y_pred)\n",
    "  input_example = X_1_test.iloc[:5]\n",
    "\n",
    "  # Log an instance of the trained model for later use\n",
    "  mlflow.xgboost.log_model(\n",
    "        xgb_clf, \n",
    "        name=\"xgb_clf\",\n",
    "        registered_model_name=\"XGB_Class_No_Feat_Eng\", # If the model name doesnâ€™t exist MLflow creates it. If it already exists MLflow automatically creates a new version\n",
    "        input_example=input_example, # A small, representative example of the kind of input the model expects\n",
    "        signature=signature # Model signature describing model input and output schema\n",
    "        )\n",
    "  \n",
    "\n",
    "print(f\"âœ… Run '{run_name}' completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60dce45",
   "metadata": {},
   "source": [
    "Metrics description \n",
    "- ROC-AUC: Measures the modelâ€™s ability to distinguish between classes\n",
    "- Accuracy: Overall correctness of the model.\n",
    "- Precision: Out of all predicted positives, how many were correct?\n",
    "- Recall (Sensitivity): Out of all actual positives, how many were detected?\n",
    "- F1 Score: Balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d696b",
   "metadata": {},
   "source": [
    "Metrics and Model Conclusion:\n",
    "\n",
    "NBA Classification â€” What Metrics Should We Use to Choose the Best Model?\n",
    "- The goal is to predict whether an NBA player would score over a certain threshold (binary classification).\n",
    "- The 60/40 imbalance has been handled with class_weight.\n",
    "- It should focus on metrics that are sensitive to both False Positives and False Negatives. Keeping in mind an accuracy of 65% might just mean it predicted the majority class correctly.\n",
    "- Primary the ROC AUC: It evaluates the model's ability to distinguish between the two classes across all possible classification thresholds.\n",
    "- Secondary F1-Score: is the harmonic mean of Precision and Recall. It provides a single number that requires the model to have high scores on both.\n",
    "- Thrid Precision and Recall: Minimizing False Positives / Minimizing False Negatives.\n",
    "\n",
    "Challenge especification: The dataset includes natural variability. Well-built models\n",
    "typically achieve around 0.80 accuracy and 0.85â€“0.90 ROC-AUC without overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a26d8b",
   "metadata": {},
   "source": [
    "Selecting the Best Model, Parameters, and Metrics from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93c4accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Name: XGB_No_Feat_run_v6\n",
      "Best Run ID: 7f161a3cd2bc463caa09d8ddb42af2df\n",
      "\n",
      "Best Run Summary Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b4ec6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b4ec6_level0_col0\" class=\"col_heading level0 col0\" >Test Accuracy</th>\n",
       "      <th id=\"T_b4ec6_level0_col1\" class=\"col_heading level0 col1\" >Test ROC-AUC</th>\n",
       "      <th id=\"T_b4ec6_level0_col2\" class=\"col_heading level0 col2\" >Test Precision</th>\n",
       "      <th id=\"T_b4ec6_level0_col3\" class=\"col_heading level0 col3\" >Test Recall</th>\n",
       "      <th id=\"T_b4ec6_level0_col4\" class=\"col_heading level0 col4\" >Test F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b4ec6_row0_col0\" class=\"data row0 col0\" >0.847778</td>\n",
       "      <td id=\"T_b4ec6_row0_col1\" class=\"data row0 col1\" >0.930173</td>\n",
       "      <td id=\"T_b4ec6_row0_col2\" class=\"data row0 col2\" >0.809240</td>\n",
       "      <td id=\"T_b4ec6_row0_col3\" class=\"data row0 col3\" >0.788099</td>\n",
       "      <td id=\"T_b4ec6_row0_col4\" class=\"data row0 col4\" >0.798529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24336164550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Parameters:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9cda9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_9cda9_level0_col0\" class=\"col_heading level0 col0\" >Parameter</th>\n",
       "      <th id=\"T_9cda9_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_9cda9_row0_col0\" class=\"data row0 col0\" >colsample_bytree</td>\n",
       "      <td id=\"T_9cda9_row0_col1\" class=\"data row0 col1\" >0.9806881870543972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9cda9_row1_col0\" class=\"data row1 col0\" >gamma</td>\n",
       "      <td id=\"T_9cda9_row1_col1\" class=\"data row1 col1\" >3.94634986154594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9cda9_row2_col0\" class=\"data row2 col0\" >learning_rate</td>\n",
       "      <td id=\"T_9cda9_row2_col1\" class=\"data row2 col1\" >0.045974998070504425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9cda9_row3_col0\" class=\"data row3 col0\" >max_depth</td>\n",
       "      <td id=\"T_9cda9_row3_col1\" class=\"data row3 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9cda9_row4_col0\" class=\"data row4 col0\" >min_child_weight</td>\n",
       "      <td id=\"T_9cda9_row4_col1\" class=\"data row4 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9cda9_row5_col0\" class=\"data row5 col0\" >n_estimators</td>\n",
       "      <td id=\"T_9cda9_row5_col1\" class=\"data row5 col1\" >250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9cda9_row6_col0\" class=\"data row6 col0\" >scale_pos_weight</td>\n",
       "      <td id=\"T_9cda9_row6_col1\" class=\"data row6 col1\" >1.4680073126142597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9cda9_row7_col0\" class=\"data row7 col0\" >subsample</td>\n",
       "      <td id=\"T_9cda9_row7_col1\" class=\"data row7 col1\" >0.8320612810134949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24336164550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"XGBoost_Classification_No_Feat_Eng\")\n",
    "\n",
    "# Fetch all runs for the experiment\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.test_roc_auc DESC\"],  # Sort by best test ROC-AUC and Accuracy\n",
    "    #order_by=[\"metrics.test_roc_auc DESC\", \"metrics.test_accuracy DESC\"],  # Sort by best test ROC-AUC and Accuracy\n",
    ")\n",
    "\n",
    "# Select the best run (first in the sorted list)\n",
    "best_run = runs[0]\n",
    "print(f\"Best Run Name: {best_run.info.run_name}\")\n",
    "print(f\"Best Run ID: {best_run.info.run_id}\")\n",
    "\n",
    "summary_data = {\n",
    "    \"Test Accuracy\": [best_run.data.metrics.get(\"test_accuracy\")],\n",
    "    \"Test ROC-AUC\": [best_run.data.metrics.get(\"test_roc_auc\")],\n",
    "    \"Test Precision\": [best_run.data.metrics.get(\"test_precision\")],\n",
    "    \"Test Recall\": [best_run.data.metrics.get(\"test_recall\")],\n",
    "    \"Test F1-Score\": [best_run.data.metrics.get(\"test_f1_score\")],\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame for a clean table\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display neatly\n",
    "print(\"\\nBest Run Summary Metrics:\")\n",
    "display(summary_df.style.hide(axis=\"index\"))\n",
    "\n",
    "# Extract best run parameters\n",
    "params_data = best_run.data.params\n",
    "\n",
    "# Convert to a DataFrame\n",
    "params_df = pd.DataFrame(list(params_data.items()), columns=[\"Parameter\", \"Value\"])\n",
    "\n",
    "# Display nicely without index\n",
    "print(\"Best Run Parameters:\")\n",
    "display(params_df.style.hide(axis=\"index\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
